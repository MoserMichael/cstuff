---
layout: post
title: Semantic nets and social networks
---

h2. {{ page.title }}
<p class="publish_date">18 July 2011</p>

Man has named child after "a Button":http://www.bbc.co.uk/news/world-middle-east-13417930 
(At least it is not "this button":http://en.wikipedia.org/wiki/Big_red_button#Symbolism )

While staying on the subject of Facebook, I wonder if you can automate creation of "semantic nets":http://en.wikipedia.org/wiki/Semantic_network) by doing statistical analysis of things that people do 'like'.  In order to do that you would need information kept by both google and facebook; Facebook knows what you 'like' (corresponding to the concepts of a semantic net) Google knows what you have searched for and how you got it (the edges between concepts) / the edges are extracted from query words. Nodes are concepts that you 'liked'. Ups now google "has that too":https://plus.google.com

This sort of research would be similar to what they are doing in Natural Language Processing, these days it's all statistics and "n-grams":http://en.wikipedia.org/wiki/N-gram With such an encompassing knowledge system the resulting Knowledge Monopoly (tm) could serve you content aware adds on future thoughts even before you have thought of them.

.. Now there was this recent science fiction idea of the "Singularity event":http://www.amazon.com/dp/0670033847/ being "near":http://www.fourmilab.ch/fourmilog/archives/2011-02/001293.html - It says that a machine capable of thought will blow away all current technological limitations and we will all shoot out for the stars, and all that should happen Really soon.

Well I don't know, even if the machine comes up with a grand plan, it will depend on the political will of Humans to implement it; so I guess that all the bots will end up sending emails to each other being largely ignored ... Just like us Humans ;-) also we might end up with a "really depressed Marvin":http://en.wikipedia.org/wiki/Marvin_the_Paranoid_Android  
<notextile>
<a name="we" >________</a>
</notextile>

h3. How to test the intelligence of machines

With the aim of furthering the Singularity event - I would now like to propose a better test that should tell if a machine is intelligent or not.

Normally a program dies when its environment changes in some unexpected ways (this is also called "Software rot":http://en.wikipedia.org/wiki/Software_rot ); I would say that a program (or any other technical system) is intelligent, if it can adapt all by itself to unexpected changes of its environment. This test would not require direct intervention of outside entities, unlike the "turing test":http://en.wikipedia.org/wiki/Turing_test  for example. I would call this intelligence test the 'Wall-E test' - name after robot "Wall-E":http://en.wikipedia.org/wiki/WALL-E who by means of intelligence and wit could adjust to a total wasteland.

Interestingly now I remember that the book "The Ghost in the Machine":http://en.wikipedia.org/wiki/The_Ghost_in_the_Machine by "Arthur Koestler":http://en.wikipedia.org/wiki/Arthur_Koestler also mentions the ability of the higher nervous system to compensate for damages in other parts of the body / psyche as a defining feature of intelligent systems. Somehow I think this happens to be a very Jewish definition of intelligence - wit and intelligence had to compensate for the very disadvantageous situation of discriminations / persecutions / deliberate prescriptions of what you may or may not do for a living.  That makes the Wall-E test a very tough test.

Somehow defining intelligence as the ability of a machine to convince with small talk may look like a stereotypically English way of looking at things, probably all these definitions of intelligence mirror some cultural preferences of the person who is framing this definition, in other words, Intelligence is defined by culture X by what culture X values most and what culture X would like the machine to do. So while some definitions may be ok for some or the most part, no single definition will ever define the whole experience of being alive / being intelligent.
 
'What is Man, what does it mean to be Human' - the famous "riddle of the mythical Sphinx":http://en.wikipedia.org/wiki/Sphinx#The_Riddle_of_the_Sphinx is now the question that the Robot asks. That question makes sense for a Sphinx - it is half man half animal, similar to the Robot. Some say that's the reason why we "will not actually build any Robots":http://zompist.wordpress.com/2011/06/24/no-singularity-for-me-mater/ , who wants a complex beast like this around? Funny, are the ancient Egyptian, Mesopotamian/Babylonian/Persian, Indian sphinxes asking any existential questions, or is it just it just the Classical Greek copy-sphinx?

